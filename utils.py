import torch
from tqdm import tqdm
import numpy as np
import pandas as pd
import argparse

medians_mean = torch.tensor([
    51.4309, 65.1785, -12.0250, 54.8314,
    82.8575, 86.3554, 81.6232, 56.3015
]).unsqueeze(1)

medians_std = torch.tensor([
    97.9711, 119.0020, 123.9675, 215.6933,
    193.0294, 190.7409, 171.7255, 139.4443
]).unsqueeze(1)


def parse_args():
    parser = argparse.ArgumentParser(
        fromfile_prefix_chars='@', description="ECG Normalizing Flow trainer"
    )
    parser.add_argument(
        "--n_channels", default=8, type=int, help="number of ECG channels"
    )
    parser.add_argument(
        "--n_scales",
        default=3,
        type=int,
        help="number of model's hierarchical scales"
    )
    parser.add_argument(
        "--n_steps",
        default=2,
        type=int,
        help="number of flow's steps per scale"
    )
    parser.add_argument(
        "--n_latent_steps",
        default=2,
        type=int,
        help="number of flow's steps applied to pixels left at each scale"
    )
    parser.add_argument(
        "--n_samples",
        default=10,
        type=int,
        help="number of samples generated by the model every 10th epoch"
    )
    parser.add_argument(
        "--neg_slope",
        default=0.1,
        type=float,
        help="negative slope of model's Leaky ReLU"
    )
    parser.add_argument(
        "--actnorm_eps", default=1e-6, type=float, help="ActNorm's epsilon"
    )
    parser.add_argument(
        "--batch", default=512, type=int, help="batch size"
    )
    parser.add_argument(
        "--lr", default=1e-4, type=float, help="learning rate"
    )
    parser.add_argument(
        "--val_frac",
        default=0.1,
        type=float,
        help="fraction of the dataset to be left as validation set"
    )
    parser.add_argument(
        "--n_epochs", default=100, type=int, help="number of epochs"
    )
    parser.add_argument(
        "--no_normalization", action="store_true", help="don't normalize"
    )
    parser.add_argument(
        "--n_workers",
        default=4,
        type=int,
        help="number of workers used in dataloader"
    )
    parser.add_argument(
        "--annot_path",
        default="./annotations.csv",
        type=str,
        help="path to the annotations file",
    )
    parser.add_argument(
        "--stats_path",
        default="./",
        type=str,
        help="path to the directory where all data related to the training " +
             "status is stored",
    )
    parser.add_argument("path", type=str, help="path to ECGs' directory")
    parsed_args = parser.parse_args()
    return parsed_args


def dataset_mean_std(dl, n_channels):
    mean = torch.zeros(n_channels, dtype=torch.float64)
    n_pixels = 0
    with tqdm(dl) as pbar:
        pbar.set_description("Calculating mean")
        for x in pbar:
            n_pixels += x.shape[0] * x.shape[2]
            x = x.transpose(1, 0).reshape(8, -1).sum(dim=1)
            mean += x
    mean = mean / n_pixels

    mean = mean.unsqueeze(1)
    std = torch.zeros(n_channels, dtype=torch.float64)
    with tqdm(dl) as pbar:
        pbar.set_description("Calculating std")
        for x in pbar:
            x = ((x - mean) ** 2).transpose(1, 0).reshape(8, -1).sum(dim=1)
            std += x
    mean = mean.squeeze(1)
    std = torch.sqrt(std / n_pixels)

    return mean, std


def train_val_split(annot_path, val_frac):
    annot_df = pd.read_csv(annot_path)
    val_annot = annot_df.sample(frac=val_frac)
    train_annot = annot_df.drop(val_annot.index)
    return train_annot.reset_index(drop=True), val_annot.reset_index(drop=True)


def sample_from_model(
        net,
        distribution,
        sample_size,
        epoch,
        device,
        n_channels,
        n_samples,
        stats_path
):
    for i in range(n_samples):
        z = distribution.sample([sample_size]).flatten().unsqueeze(0)
        with torch.no_grad():
            x = net.reverse(z.double().to(device))
        x = x.cpu().detach().numpy().reshape((n_channels, -1)).transpose(1, 0)
        np.savetxt(
            f'{stats_path}/training-samples/{epoch}-{i}.asc', x, delimiter=' '
        )
